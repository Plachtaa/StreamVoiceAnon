_target_: modules.vqgan.modules.firefly_encoder.FireflyArchitecture
spec_transform:
  _target_: modules.vqgan.spectrogram.LogMelSpectrogram
  sample_rate: 44100
  n_mels: 160
  n_fft: 2048
  hop_length: 512
  win_length: 2048
backbone:
  _target_: modules.vqgan.modules.firefly.ConvNeXtEncoder
  input_channels: 160
  depths: [3, 3, 9, 3]
  dims: [128, 256, 384, 512]
  drop_path_rate: 0.2
  kernel_size: 7
head:
  _target_: modules.vqgan.modules.firefly.ConvNeXtEncoder
  input_channels: 512
  depths: [3, 3, 3, 3]
  dims: [640, 768, 896, 1024]
  drop_path_rate: 0.2
  kernel_size: 7
  gin_channels: 192
quantizer:
  _target_: modules.vqgan.modules.bsq_no_upsample.DownsampleBinarySphericalQuantize
  input_dim: 512
  n_groups: 1
  codebook_size: 8192
  downsample_factor: [2, 2]
  post_module: &transformer_module
    _target_: modules.vqgan.windowed_transformer.WindowLimitedTransformer
    causal: true
    window_size: 512
    config: &transformer_config
      _target_: modules.vqgan.windowed_transformer.ModelArgs
      block_size: 2048
      n_layer: 8
      n_head: 8
      dim: 512
      intermediate_size: 1536
      n_local_heads: -1
      head_dim: 64
      rope_base: 10000
      dropout_rate: 0.1
      attn_dropout_rate: 0.1
  pre_module: *transformer_module